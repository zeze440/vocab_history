# data_loader.py - ë°ì´í„° ë¡œë”© ìœ í‹¸ë¦¬í‹°

import os
import glob
import pandas as pd
from utils import safe_read_csv


def find_text_column(df):
    """í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ìë™ìœ¼ë¡œ ì°¾ëŠ” í•¨ìˆ˜ - ìˆ˜ì •ëœ ë²„ì „"""

    # ğŸ”¥ ìš°ì„ ìˆœìœ„ë³„ ì»¬ëŸ¼ëª… ëª©ë¡ (content ì¶”ê°€)
    priority_columns = [
        "content",  # ğŸ”¥ ìƒˆë¡œ ì¶”ê°€ - ê°€ì¥ ë†’ì€ ìš°ì„ ìˆœìœ„
        "text",
        "passage",
        "content_text",
        "paragraph",
        "article",
        "body",
        "description",
        "story",
        "passage_text",
    ]

    # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ê²€ìƒ‰
    columns_lower = [col.lower() for col in df.columns]

    # ìš°ì„ ìˆœìœ„ë³„ë¡œ ê²€ìƒ‰
    for target in priority_columns:
        if target.lower() in columns_lower:
            # ì‹¤ì œ ì»¬ëŸ¼ëª… ì°¾ê¸°
            actual_column = df.columns[columns_lower.index(target.lower())]
            print(f"âœ… í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ë°œê²¬: '{actual_column}'")
            return actual_column

    # ğŸ”¥ ë¶€ë¶„ ë§¤ì¹˜ ê²€ìƒ‰ (ë” ìœ ì—°í•œ ê²€ìƒ‰)
    for col in df.columns:
        col_lower = col.lower()
        if any(
            keyword in col_lower for keyword in ["content", "text", "passage", "body"]
        ):
            print(f"âœ… í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ë°œê²¬ (ë¶€ë¶„ë§¤ì¹˜): '{col}'")
            return col

    # ğŸ”¥ ë°ì´í„° ê¸¸ì´ ê¸°ë°˜ ì¶”ì¸¡
    text_candidates = []
    for col in df.columns:
        if df[col].dtype == "object":  # ë¬¸ìì—´ ì»¬ëŸ¼ë§Œ
            # í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°
            avg_length = df[col].astype(str).str.len().mean()
            if avg_length > 50:  # í‰ê·  50ì ì´ìƒì´ë©´ í…ìŠ¤íŠ¸ì¼ ê°€ëŠ¥ì„±
                text_candidates.append((col, avg_length))

    if text_candidates:
        # ê°€ì¥ ê¸´ í‰ê·  ê¸¸ì´ë¥¼ ê°€ì§„ ì»¬ëŸ¼ ì„ íƒ
        best_column = max(text_candidates, key=lambda x: x[1])[0]
        print(
            f"âœ… í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì¶”ì •: '{best_column}' (í‰ê·  ê¸¸ì´: {max(text_candidates, key=lambda x: x[1])[1]:.1f}ì)"
        )
        return best_column

    # ë§ˆì§€ë§‰ ì‹œë„: ì²« ë²ˆì§¸ object íƒ€ì… ì»¬ëŸ¼
    for col in df.columns:
        if df[col].dtype == "object":
            print(f"âš ï¸ ê¸°ë³¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì‚¬ìš©: '{col}'")
            return col

    raise ValueError("í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")


def load_user_words_data(file_path):
    """ì‚¬ìš©ì ë‹¨ì–´ ë°ì´í„° ë¡œë”© - ê¸°ì¡´ê³¼ ë™ì¼"""
    print(f"ğŸ“š ì‚¬ìš©ì ë‹¨ì–´ ë°ì´í„° ë¡œë”©: {file_path}")

    if not os.path.exists(file_path):
        print(f"âš ï¸ ì‚¬ìš©ì ë‹¨ì–´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return [], []

    try:
        df = safe_read_csv(file_path)

        if df is None or df.empty:
            print("âš ï¸ ë¹ˆ ì‚¬ìš©ì ë‹¨ì–´ íŒŒì¼ì…ë‹ˆë‹¤")
            return [], []

        # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ë‹¨ì–´ë¡œ ì‚¬ìš©
        word_column = df.columns[0]
        words = df[word_column].dropna().astype(str).tolist()

        # ë‹¨ì–´ì™€ ìˆ™ì–´ ë¶„ë¦¬
        single_words = [w.strip() for w in words if w.strip() and " " not in w.strip()]
        idioms = [w.strip() for w in words if w.strip() and " " in w.strip()]

        print(f"   âœ… ì‚¬ìš©ì ë‹¨ì–´: {len(single_words)}ê°œ")
        print(f"   âœ… ì‚¬ìš©ì ìˆ™ì–´: {len(idioms)}ê°œ")

        return single_words, idioms

    except Exception as e:
        print(f"âŒ ì‚¬ìš©ì ë‹¨ì–´ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        return [], []


def load_texts_data(file_path):
    """ì§€ë¬¸ ë°ì´í„° ë¡œë”© - ìˆ˜ì •ëœ ë²„ì „ (ì§€ë¬¸ DB ì •ë³´ í¬í•¨)"""
    print(f"ğŸ“– ì§€ë¬¸ ë°ì´í„° ë¡œë”©: {file_path}")

    if not os.path.exists(file_path):
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")

    try:
        # CSV íŒŒì¼ ì½ê¸°
        df = safe_read_csv(file_path)

        if df is None or df.empty:
            raise ValueError("ë¹ˆ ë°ì´í„°íŒŒì¼ì…ë‹ˆë‹¤")

        print(f"   ğŸ“Š ì „ì²´ í–‰ ìˆ˜: {len(df)}")
        print(f"   ğŸ“Š ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
        print(f"   ğŸ“Š ì»¬ëŸ¼ë“¤: {df.columns.tolist()}")

        # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì°¾ê¸°
        text_column = find_text_column(df)

        # ğŸ”¥ ìœ íš¨í•œ í…ìŠ¤íŠ¸ë§Œ í•„í„°ë§í•˜ë˜ ì§€ë¬¸ DB ì •ë³´ ëª¨ë‘ í¬í•¨
        valid_texts = []
        for idx, row in df.iterrows():
            text_content = row[text_column]

            # None, NaN, ë¹ˆ ë¬¸ìì—´ ì²´í¬
            if pd.isna(text_content) or not str(text_content).strip():
                continue

            text_str = str(text_content).strip()

            # ìµœì†Œ ê¸¸ì´ ì²´í¬ (10ì ì´ìƒ)
            if len(text_str) < 10:
                continue

            # ğŸ”¥ ID ìƒì„± (textbook_studio_passage_id ìš°ì„  ì‚¬ìš©)
            if "textbook_studio_passage_id" in df.columns and pd.notna(
                row["textbook_studio_passage_id"]
            ):
                text_id = str(row["textbook_studio_passage_id"])
            elif "textbook_id" in df.columns:
                text_id = f"text_{row['textbook_id']}"
            else:
                text_id = f"text_{idx + 1}"

            # ğŸ”¥ ì§€ë¬¸ DBì˜ ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ë°˜í™˜
            text_info = {
                "id": text_id,
                "content": text_str,
                "original_index": idx,
                # ğŸ”¥ ì§€ë¬¸ DB ë©”íƒ€ë°ì´í„° ì¶”ê°€
                "textbook_id": row.get("textbook_id", None),
                "product_id": row.get("product_id", None),
                "textbook_studio_passage_id": row.get(
                    "textbook_studio_passage_id", None
                ),
                "textbook_unit_id": row.get("textbook_unit_id", None),
                "book_title": row.get("book_title", None),
                "studio_title": row.get("studio_title", None),
                "studio_series": row.get("studio_series", None),
                "studio_title2": row.get("studio_title2", None),
                "textbook_studio_passage_title": row.get(
                    "textbook_studio_passage_title", None
                ),
                "passage_order": row.get("passage_order", None),
                # ì›ë³¸ í–‰ ì •ë³´ë„ í¬í•¨ (í•„ìš”ì‹œ ì‚¬ìš©)
                "original_row": row.to_dict(),
            }

            valid_texts.append(text_info)

        print(f"   âœ… ìœ íš¨í•œ í…ìŠ¤íŠ¸: {len(valid_texts)}ê°œ")

        if not valid_texts:
            raise ValueError("ìœ íš¨í•œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")

        return valid_texts

    except Exception as e:
        print(f"âŒ ì§€ë¬¸ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        raise


def load_custom_idioms_from_data_directory(data_dir: str = "data") -> list:
    """data ë””ë ‰í† ë¦¬ì—ì„œ ìˆ™ì–´ ë¡œë“œ"""
    idioms = set()
    loading_summary = []

    print(f"ğŸ“ data ë””ë ‰í† ë¦¬ ìˆ™ì–´ ë¡œë”© ì‹œì‘: {data_dir}")

    if not os.path.exists(data_dir):
        print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_dir}")
        return []

    file_patterns = ["*.csv", "*.txt", "*.xlsx", "*.xls"]
    all_files = []
    for pattern in file_patterns:
        all_files.extend(glob.glob(os.path.join(data_dir, pattern)))

    print(f"ğŸ” ë°œê²¬ëœ íŒŒì¼ ìˆ˜: {len(all_files)}ê°œ")

    for file_path in all_files:
        filename = os.path.basename(file_path)
        file_ext = os.path.splitext(filename)[1].lower()
        file_idioms_count = 0

        try:
            print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {filename}")

            if file_ext == ".csv":
                file_idioms_count = _load_csv_idioms(file_path, idioms)
            elif file_ext == ".txt":
                file_idioms_count = _load_txt_idioms(file_path, idioms)
            elif file_ext in [".xlsx", ".xls"]:
                file_idioms_count = _load_excel_idioms(file_path, idioms)

            loading_summary.append(
                {
                    "file": filename,
                    "type": file_ext,
                    "loaded_count": file_idioms_count,
                    "status": "success" if file_idioms_count > 0 else "empty",
                }
            )

        except Exception as e:
            print(f"   âŒ {filename} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            loading_summary.append(
                {
                    "file": filename,
                    "type": file_ext,
                    "loaded_count": 0,
                    "status": "failed",
                    "error": str(e),
                }
            )

    final_idioms = sorted(set(idioms))
    print(f"\nğŸ“Š data ë””ë ‰í† ë¦¬ ë¡œë”© ì™„ë£Œ: ì´ {len(final_idioms)}ê°œ ìˆ™ì–´")
    return final_idioms


def _load_csv_idioms(file_path, idioms):
    """CSV íŒŒì¼ì—ì„œ ìˆ™ì–´ ë¡œë“œ"""
    df = safe_read_csv(file_path)
    if df is None:
        return 0

    possible_columns = ["phrase", "idiom", "expression", "text", "content", "ì›í˜•"]
    target_column = next(
        (
            col
            for col in df.columns
            if col.lower() in [c.lower() for c in possible_columns]
        ),
        df.columns[0] if len(df.columns) > 0 else None,
    )

    if target_column and target_column in df.columns:
        phrases = df[target_column].dropna().astype(str).str.strip().str.lower()
        phrases = phrases[phrases != ""].unique()
        valid_phrases = [
            phrase
            for phrase in phrases
            if 2 <= len(phrase.split()) <= 8
            and len(phrase) <= 100
            and phrase.replace(" ", "").replace("-", "").isalpha()
        ]
        idioms.update(valid_phrases)
        file_idioms_count = len(valid_phrases)
        print(f"   âœ… CSV: {file_idioms_count}ê°œ ì¶”ì¶œ (ì»¬ëŸ¼: {target_column})")
        return file_idioms_count

    return 0


def _load_txt_idioms(file_path, idioms):
    """TXT íŒŒì¼ì—ì„œ ìˆ™ì–´ ë¡œë“œ"""
    from config import ENCODING_ORDER

    for encoding in ENCODING_ORDER:
        try:
            with open(file_path, "r", encoding=encoding) as f:
                lines = f.readlines()
            phrases = [
                line.strip().lower()
                for line in lines
                if line.strip()
                and not line.startswith(("#", "//"))
                and 2 <= len(line.split()) <= 8
                and len(line) <= 100
            ]
            idioms.update(phrases)
            file_idioms_count = len(phrases)
            print(f"   âœ… TXT: {file_idioms_count}ê°œ ì¶”ì¶œ (ì¸ì½”ë”©: {encoding})")
            return file_idioms_count
        except UnicodeDecodeError:
            continue

    print(f"   âŒ TXT: ëª¨ë“  ì¸ì½”ë”© ì‹¤íŒ¨")
    return 0


def _load_excel_idioms(file_path, idioms):
    """Excel íŒŒì¼ì—ì„œ ìˆ™ì–´ ë¡œë“œ"""
    excel_file = pd.ExcelFile(file_path)
    total_phrases = []

    for sheet_name in excel_file.sheet_names:
        try:
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            possible_columns = [
                "phrase",
                "idiom",
                "expression",
                "text",
                "content",
                "ì›í˜•",
            ]
            target_column = next(
                (
                    col
                    for col in df.columns
                    if col.lower() in [c.lower() for c in possible_columns]
                ),
                df.columns[0] if len(df.columns) > 0 else None,
            )
            if target_column and target_column in df.columns:
                phrases = df[target_column].dropna().astype(str).str.strip().str.lower()
                phrases = phrases[phrases != ""].unique()
                valid_phrases = [
                    phrase
                    for phrase in phrases
                    if 2 <= len(phrase.split()) <= 8
                    and len(phrase) <= 100
                    and phrase.replace(" ", "").replace("-", "").isalpha()
                ]
                total_phrases.extend(valid_phrases)
                print(f"      ğŸ“‹ {sheet_name}: {len(valid_phrases)}ê°œ")
        except Exception as e:
            print(f"      âŒ {sheet_name} ì‹œíŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    idioms.update(total_phrases)
    file_idioms_count = len(total_phrases)
    print(f"   âœ… Excel: ì´ {file_idioms_count}ê°œ ì¶”ì¶œ")
    return file_idioms_count
