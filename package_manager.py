# package_manager.py - íŒ¨í‚¤ì§€ ì´ˆê¸°í™” ë° ê²€ì¦

import os
import sys

# ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
spacy = None
nlp = None
openai = None
client = None
nltk = None
lemmatizer = None


def safe_import_packages():
    """í•„ìˆ˜ íŒ¨í‚¤ì§€ë“¤ì„ ì•ˆì „í•˜ê²Œ import"""
    global spacy, openai, nltk, nlp, lemmatizer, client

    # ğŸ”¥ .env íŒŒì¼ ë¡œë“œ (ë§¨ ìœ„ì— ì¶”ê°€)
    try:
        from dotenv import load_dotenv
        load_dotenv()
        print("âœ… .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
    except ImportError:
        print("âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. pip install python-dotenv")
    except Exception as e:
        print(f"âš ï¸ .env ë¡œë“œ ì‹¤íŒ¨: {e}")
    # SpaCy ì´ˆê¸°í™”
    try:
        import spacy

        nlp = spacy.load("en_core_web_sm")
    except ImportError:
        print(
            "âŒ spacyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install spacy' ì‹¤í–‰ í›„ 'python -m spacy download en_core_web_sm' ì‹¤í–‰í•˜ì„¸ìš”."
        )
        return False
    except OSError:
        print(
            "âŒ spacy ì˜ì–´ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. 'python -m spacy download en_core_web_sm' ì‹¤í–‰í•˜ì„¸ìš”."
        )
        return False

    # OpenAI ì´ˆê¸°í™”
    try:
        import openai

        # OpenAI API í‚¤ ê²€ì¦
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ ë‹¤ìŒ ì¤‘ í•œ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”:")
            print("   1. export OPENAI_API_KEY='your-api-key-here'")
            print("   2. .env íŒŒì¼ì— OPENAI_API_KEY=your-api-key-here ì¶”ê°€")
            print("   3. ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •")
            return False

        try:
            client = openai.OpenAI(api_key=api_key)
            # API í‚¤ ìœ íš¨ì„± ê°„ë‹¨ í…ŒìŠ¤íŠ¸
            test_response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=5,
            )
            print("âœ… OpenAI API ì—°ê²° ë° ì¸ì¦ ì„±ê³µ")
        except openai.AuthenticationError:
            print("âŒ OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return False
        except openai.RateLimitError:
            print("âš ï¸ OpenAI API ì‚¬ìš©ëŸ‰ í•œë„ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            return False
        except openai.APIError as e:
            print(f"âŒ OpenAI API ì˜¤ë¥˜: {e}")
            return False
        except Exception as e:
            print(f"âŒ OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    except ImportError:
        print("âŒ openaiê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install openai' ì‹¤í–‰í•˜ì„¸ìš”.")
        return False

    # NLTK ì´ˆê¸°í™”
    try:
        import nltk
        from nltk.stem import WordNetLemmatizer

        lemmatizer = WordNetLemmatizer()

        # NLTK ë°ì´í„° í™•ì¸
        required_nltk_data = [
            ("tokenizers/punkt", "punkt"),
            ("corpora/wordnet", "wordnet"),
            ("taggers/averaged_perceptron_tagger", "averaged_perceptron_tagger"),
            ("corpora/stopwords", "stopwords"),
        ]

        for data_path, download_name in required_nltk_data:
            try:
                nltk.data.find(data_path)
            except LookupError:
                print(f"ğŸ“¦ NLTK {download_name} ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
                try:
                    nltk.download(download_name, quiet=True)
                except Exception as e:
                    print(f"âš ï¸ NLTK {download_name} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                    print("ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")

    except ImportError:
        print("âŒ nltkê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install nltk' ì‹¤í–‰í•˜ì„¸ìš”.")
        return False

    return True


def get_nlp_model():
    """SpaCy ëª¨ë¸ ë°˜í™˜"""
    global nlp
    return nlp


def get_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    global client
    return client


def get_lemmatizer():
    """NLTK Lemmatizer ë°˜í™˜"""
    global lemmatizer
    return lemmatizer


def initialize_packages():
    """íŒ¨í‚¤ì§€ ì´ˆê¸°í™” ì‹¤í–‰"""
    if not safe_import_packages():
        print("âŒ í•„ìˆ˜ íŒ¨í‚¤ì§€ import ì‹¤íŒ¨. ì œí•œëœ ëª¨ë“œë¡œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
        return False
    return True
