"""
AdvancedVocabExtractor í´ë˜ìŠ¤ì— ì¶”ê°€í•  ëˆ„ë½ëœ ë©”ì„œë“œë“¤
"""


def add_missing_methods_to_extractor():
    """
    AdvancedVocabExtractor í´ë˜ìŠ¤ì— ì¶”ê°€í•  ë©”ì„œë“œë“¤ì„ ë°˜í™˜
    ì‹¤ì œë¡œëŠ” ì´ í•¨ìˆ˜ë“¤ì„ í´ë˜ìŠ¤ì— ë™ì ìœ¼ë¡œ ë°”ì¸ë”©í•˜ê±°ë‚˜
    ìƒì†ì„ í†µí•´ ì¶”ê°€í•  ìˆ˜ ìˆìŒ
    """

    def extract_advanced_idioms_safely(self, text_str):
        """ì•ˆì „í•œ ìˆ™ì–´ ì¶”ì¶œ"""
        try:
            return self.extract_advanced_idioms(text_str)
        except Exception as e:
            print(f"âš ï¸ ì•ˆì „í•œ ìˆ™ì–´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def extract_difficult_words_safely(
        self, text_str, easy_words, child_vocab, freq_tiers
    ):
        """ì•ˆì „í•œ ì–´ë ¤ìš´ ë‹¨ì–´ ì¶”ì¶œ"""
        try:
            return self.extract_difficult_words(
                text_str, easy_words, child_vocab, freq_tiers
            )
        except Exception as e:
            print(f"âš ï¸ ì•ˆì „í•œ ë‹¨ì–´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def _process_words_with_gpt_filter(self, word_candidates):
        """GPT í•„í„°ë¥¼ ì‚¬ìš©í•œ ë‹¨ì–´ ì²˜ë¦¬"""
        if hasattr(self, "gpt_filter") and self.gpt_filter:
            # GPT í•„í„° ë¡œì§ (ê°„ë‹¨í•œ êµ¬í˜„)
            print(f"   ğŸ¤– GPT í•„í„°ë§ ëª¨ë“œ: {len(word_candidates)}ê°œ í›„ë³´")
            return self._process_words_without_gpt_filter(word_candidates, {})
        else:
            return self._process_words_without_gpt_filter(word_candidates, {})

    def _gpt_analyze_word_difficulty(self, word, context="", pos=""):
        """GPT ê¸°ë°˜ ë‹¨ì–´ ë‚œì´ë„ ë¶„ì„ (ê¸°ë³¸ êµ¬í˜„)"""
        return {
            "difficulty_score": 5.0,
            "contextual_difficulty": 5.0,
            "recommendation": "exclude",
            "reasoning": "ê¸°ë³¸ ë¶„ì„ - GPT ì—°ë™ ë¯¸êµ¬í˜„",
            "is_basic_vocabulary": len(word) < 4,
        }

    return {
        "extract_advanced_idioms_safely": extract_advanced_idioms_safely,
        "extract_difficult_words_safely": extract_difficult_words_safely,
        "_process_words_with_gpt_filter": _process_words_with_gpt_filter,
        "_gpt_analyze_word_difficulty": _gpt_analyze_word_difficulty,
    }


class MissingMethodsMixin:
    """ëˆ„ë½ëœ ë©”ì„œë“œë“¤ì„ ì œê³µí•˜ëŠ” Mixin í´ë˜ìŠ¤"""

    def extract_advanced_idioms_safely(self, text_str):
        """ì•ˆì „í•œ ìˆ™ì–´ ì¶”ì¶œ"""
        try:
            return self.extract_advanced_idioms(text_str)
        except Exception as e:
            print(f"âš ï¸ ì•ˆì „í•œ ìˆ™ì–´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def extract_difficult_words_safely(
        self, text_str, easy_words, child_vocab, freq_tiers
    ):
        """ì•ˆì „í•œ ì–´ë ¤ìš´ ë‹¨ì–´ ì¶”ì¶œ"""
        try:
            return self.extract_difficult_words(
                text_str, easy_words, child_vocab, freq_tiers
            )
        except Exception as e:
            print(f"âš ï¸ ì•ˆì „í•œ ë‹¨ì–´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def _process_words_with_gpt_filter(self, word_candidates):
        """GPT í•„í„°ë¥¼ ì‚¬ìš©í•œ ë‹¨ì–´ ì²˜ë¦¬"""
        if hasattr(self, "gpt_filter") and self.gpt_filter:
            print(f"   ğŸ¤– GPT í•„í„°ë§ ëª¨ë“œ: {len(word_candidates)}ê°œ í›„ë³´")
            return self._process_words_without_gpt_filter(word_candidates, {})
        else:
            return self._process_words_without_gpt_filter(word_candidates, {})

    def _gpt_analyze_word_difficulty(self, word, context="", pos=""):
        """GPT ê¸°ë°˜ ë‹¨ì–´ ë‚œì´ë„ ë¶„ì„"""
        return {
            "difficulty_score": 5.0,
            "contextual_difficulty": 5.0,
            "recommendation": "exclude",
            "reasoning": "ê¸°ë³¸ ë¶„ì„ - GPT ì—°ë™ ë¯¸êµ¬í˜„",
            "is_basic_vocabulary": len(word) < 4,
        }
